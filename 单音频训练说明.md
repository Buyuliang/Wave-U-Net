# 单音频训练和预测功能说明

## 已完成的工作

我已经为您创建了一个完整的单音频训练和预测系统，包含以下文件：

1. **SingleAudioTrainPredict.py** - 主脚本，支持单音频训练和预测
2. **SINGLE_AUDIO_USAGE.md** - 详细的使用说明文档
3. **quick_start_example.sh** - 快速开始示例脚本

## 功能概述

### 主要功能

1. **单音频训练**
   - 支持从单个音频文件（混合音频 + 可选的分离源）进行训练
   - 自动处理音频预处理（重采样、通道处理、padding）
   - 支持数据增强
   - 可配置训练参数（轮数、步数、学习率等）

2. **自动预测**
   - 训练完成后自动使用训练好的模型进行预测
   - 支持仅预测模式（使用预训练模型）
   - 自动保存分离后的音频文件

3. **灵活配置**
   - 支持使用 Config.py 中的所有模型配置
   - 可自定义输出路径和模型保存路径
   - 支持多种音频格式

## 训练流程追踪

### 1. 数据加载阶段
```
输入音频文件 → 加载混合音频 → 加载源文件（可选）→ 预处理
```

### 2. 数据集创建阶段
```
音频数组 → Padding → 提取片段 → TensorFlow 数据集 → 数据增强 → 批处理
```

### 3. 模型训练阶段
```
构建模型 → 计算损失 → 优化器 → 训练循环 → 保存模型
```

### 4. 预测阶段
```
加载模型 → 处理输入音频 → 模型推理 → 后处理 → 保存结果
```

## 快速开始

### 方法 1: 仅预测（使用预训练模型）

```bash
python SingleAudioTrainPredict.py with cfg.full_44KHz \
    input_audio_path="your_audio.mp3" \
    predict_only=True \
    model_save_path="checkpoints/full_44KHz/full_44KHz-236118"
```

### 方法 2: 训练 + 预测（有源文件）

```bash
python SingleAudioTrainPredict.py with cfg.full_44KHz \
    input_audio_path="mix.wav" \
    vocals_path="vocals.wav" \
    accompaniment_path="accompaniment.wav" \
    num_epochs=10 \
    steps_per_epoch=100
```

### 方法 3: 使用示例音频测试

```bash
python SingleAudioTrainPredict.py with cfg.full_44KHz \
    input_audio_path="audio_examples/The Mountaineering Club - Mallory/mix.mp3" \
    predict_only=True \
    model_save_path="checkpoints/full_44KHz/full_44KHz-236118"
```

## 输出说明

### 训练输出
- 模型检查点保存在 `checkpoints/single_audio_{experiment_id}/` 目录
- 训练日志显示损失值和训练进度

### 预测输出
- 分离后的音频文件保存在输出目录（默认为输入文件同目录下的 `{filename}_separated` 文件夹）
- 文件命名格式：`{原文件名}_vocals.wav` 和 `{原文件名}_accompaniment.wav`

## 重要提示

1. **训练数据质量**：
   - 如果提供分离的源文件（vocals 和 accompaniment），训练效果会更好
   - 如果没有源文件，脚本会使用简单的估计方法，但效果会很差

2. **模型配置**：
   - 推荐使用 `cfg.full_44KHz` 用于人声分离（44.1 KHz，最佳质量）
   - 使用 `cfg.full` 用于 22.05 KHz 采样率
   - 使用 `cfg.full_multi_instrument` 用于多乐器分离

3. **训练参数调整**：
   - `num_epochs`: 训练轮数，建议 10-20
   - `steps_per_epoch`: 每轮步数，建议 100-200
   - `learning_rate`: 学习率，默认 1e-4，可根据需要调整

4. **性能考虑**：
   - 单音频训练通常比完整数据集训练快得多
   - 但模型可能过拟合到单个音频
   - 如果可能，建议使用预训练模型进行预测

## 代码结构

### 主要函数

1. **create_single_audio_dataset()**
   - 从音频文件加载数据
   - 处理重采样和通道
   - 返回混合音频和源音频字典

2. **create_tf_dataset_from_audio()**
   - 从音频数组创建 TensorFlow 数据集
   - 处理 padding 和片段提取
   - 返回可用于训练的数据集

3. **train_single_audio()**
   - 构建模型
   - 设置训练流程
   - 执行训练循环
   - 保存模型

4. **main()**
   - 主函数，协调训练和预测流程
   - 处理参数和配置

## 与原始训练流程的对比

| 特性 | 原始训练 (Training.py) | 单音频训练 (SingleAudioTrainPredict.py) |
|------|----------------------|----------------------------------------|
| 数据源 | MUSDB 完整数据集 | 单个音频文件 |
| 训练时间 | 数小时到数天 | 几分钟到几十分钟 |
| 模型质量 | 通用，泛化好 | 可能过拟合到单个音频 |
| 适用场景 | 生产环境，需要高质量模型 | 快速测试，单音频优化 |

## 下一步建议

1. **测试脚本**：使用项目中的示例音频测试功能
2. **准备数据**：如果有自己的音频和分离源，可以尝试训练
3. **参数调优**：根据结果调整训练参数
4. **使用预训练模型**：如果只是需要分离音频，建议使用预训练模型

## 故障排除

如果遇到问题，请检查：
1. 音频文件路径是否正确
2. 模型配置是否匹配
3. 是否有足够的磁盘空间
4. TensorFlow 版本是否兼容

更多详细信息请参考 `SINGLE_AUDIO_USAGE.md` 文件。
